"""
LLMå·¥å‚æ¨¡å—
æ”¯æŒå¤šç§LLMæä¾›å•†ï¼Œéµå¾ªä½è€¦åˆåŸåˆ™
"""
from typing import Optional
from langchain_community.chat_models import ChatZhipuAI
from langchain_community.chat_models import ChatOpenAI
from langchain_core.language_models import BaseLanguageModel
from config.settings import settings
from utils.logger import setup_logger

logger = setup_logger("LLMFactory")


class LLMFactory:
    """LLMå·¥å‚ç±»ï¼Œç”¨äºåˆ›å»ºä¸åŒæä¾›å•†çš„LLMå®ä¾‹"""
    
    @staticmethod
    def create_llm(
        provider: Optional[str] = None,
        model_name: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None
    ) -> BaseLanguageModel:
        """
        åˆ›å»ºLLMå®ä¾‹
        
        Args:
            provider: LLMæä¾›å•† (zhipu/openai/iflytek)ï¼Œé»˜è®¤ä»é…ç½®è¯»å–
            model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä»é…ç½®è¯»å–
            temperature: æ¸©åº¦å‚æ•°ï¼Œé»˜è®¤ä»é…ç½®è¯»å–
            max_tokens: æœ€å¤§tokenæ•°ï¼Œé»˜è®¤ä»é…ç½®è¯»å–
        
        Returns:
            LLMå®ä¾‹
        """
        provider = provider or settings.LLM_PROVIDER
        model_name = model_name or settings.MODEL_NAME
        temperature = temperature if temperature is not None else settings.TEMPERATURE
        max_tokens = max_tokens or settings.MAX_TOKENS
        
        logger.info(f"ğŸ¤– æ­£åœ¨åˆ›å»ºLLMå®ä¾‹: provider={provider}, model={model_name}")
        
        try:
            if provider == "zhipu":
                return LLMFactory._create_zhipu(model_name, temperature, max_tokens)
            elif provider == "openai":
                return LLMFactory._create_openai(model_name, temperature, max_tokens)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„LLMæä¾›å•†: {provider}")
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºLLMå¤±è´¥: {e}")
            raise
    
    @staticmethod
    def _create_zhipu(model_name: str, temperature: float, max_tokens: int) -> ChatZhipuAI:
        """åˆ›å»ºæ™ºè°±æ¸…è¨€LLM"""
        if not settings.ZHIPU_API_KEY:
            raise ValueError("âŒ æœªé…ç½®ZHIPU_API_KEYï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶")
        
        return ChatZhipuAI(
            model=model_name,
            temperature=temperature,
            max_tokens=max_tokens,
            api_key=settings.ZHIPU_API_KEY,
        )
    
    @staticmethod
    def _create_openai(model_name: str, temperature: float, max_tokens: int) -> ChatOpenAI:
        """åˆ›å»ºOpenAI LLM"""
        if not settings.OPENAI_API_KEY:
            raise ValueError("âŒ æœªé…ç½®OPENAI_API_KEYï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶")
        
        return ChatOpenAI(
            model=model_name,
            temperature=temperature,
            max_tokens=max_tokens,
            api_key=settings.OPENAI_API_KEY,
        )


# ä¾¿æ·å‡½æ•°
def get_llm(**kwargs) -> BaseLanguageModel:
    """è·å–LLMå®ä¾‹çš„ä¾¿æ·å‡½æ•°"""
    return LLMFactory.create_llm(**kwargs)

