"""
LLMåˆå§‹åŒ–æ¨¡å—
è´Ÿè´£åˆ›å»ºå’Œé…ç½®LLMå®ä¾‹
"""
from typing import Optional
from langchain_core.language_models.base import BaseLanguageModel
from utils.llm_factory import get_llm
from utils.logger import setup_logger

logger = setup_logger("InitLLM")


def initialize_llm(
    provider: Optional[str] = None,
    model_name: Optional[str] = None,
    temperature: Optional[float] = None,
    max_tokens: Optional[int] = None
) -> BaseLanguageModel:
    """
    åˆå§‹åŒ–LLMå®ä¾‹
    
    Args:
        provider: LLMæä¾›å•† (zhipu/openai)ï¼Œé»˜è®¤ä»é…ç½®è¯»å–
        model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä»é…ç½®è¯»å–
        temperature: æ¸©åº¦å‚æ•°ï¼Œé»˜è®¤ä»é…ç½®è¯»å–
        max_tokens: æœ€å¤§tokenæ•°ï¼Œé»˜è®¤ä»é…ç½®è¯»å–
    
    Returns:
        LLMå®ä¾‹
    """
    logger.info("ğŸ¤– å¼€å§‹åˆå§‹åŒ–LLM...")
    
    try:
        llm = get_llm(
            provider=provider,
            model_name=model_name,
            temperature=temperature,
            max_tokens=max_tokens
        )
        logger.info("âœ… LLMåˆå§‹åŒ–æˆåŠŸ")
        return llm
    except Exception as e:
        logger.error(f"âŒ LLMåˆå§‹åŒ–å¤±è´¥: {e}")
        raise

